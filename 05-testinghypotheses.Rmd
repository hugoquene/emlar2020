# Testing hypotheses {#ch:testinghypotheses}

## formula

When testing hypotheses, and building regression models, we need to
    specify the relations between variables. This is done in
    R  by means of a *formula*, which is needed in many
    statistical functions. In general, such a formula consists of a
    response variable, followed by the tilde symbol
    [`~`]{style="color: blue"}, followed by a list of independent
    variables and/or factors [@wilk73].
In this list, the colon
    `:` indicates an interaction effect (instead
    of the sequence operator), and the asterisk
    `*` is shorthand for main effects plus
    interactions (instead of the multiplication operator). 
    By default,
    the intercept `~1` is included in the
    formula, unless suppressed explicitly
    (`-1`). We have already encountered such a formula
    in the boxplot example above.

```{r 5.1.1, echo=FALSE}
set.seed(17)
thematrix <- matrix( c(1,0.8,0.5, 0.8,1,0.7, 0.5,0.7,1), nrow=3, ncol=3 )
require(MASS) # for mvrnorm
mvrnorm(100, mu=c(1,2,3), Sigma=thematrix) -> mvdata
x1<-mvdata[,1]; x2<-mvdata[,2]; y<-mvdata[,3]
rm(mvdata)
```

```{text}
y ~ x1 + x2 # only main effects 
y ~ x1 * x2 # shorthand for x1 + x2 + (x1:x2) 
```

Consult the help files for further information on how to specify
    complex models.

## $t$ test
There are three ways to use the t test. 

In a one-sample test, the mean is compared against an expected mean,
    with
```{r 5.2.1}
t.test( x1, mu=0.80 )
```

In a two-sample test with independent observations, we often compare
    the same dependent variable, broken down by an independent
    variable.
```{r 5.2.2}
t.test( y[x1<median(x1)], y[x1>median(x1)] ) # y split up by median of x1
```

This could also be achieved by specifying the dependent and
    independent variables in a formula:\
```{r 5.2.3}
t.test( y ~ (x1<median(x1)) ) # equivalent
```

In a two-sample test with paired observations, we often compare two
    different observations, stored in two different variables.
```{r 5.2.4}
t.test( x1, x2 )
```

Note that the number of observations in the test (and hence d.f.)
    varies in these examples.

## `chisq.test`

First, let us create two categorical variables, derived from a
    speaker's `age` (in years) and average `phraselength` (in
    syllables), for 80 speakers in the Corpus of Spoken Dutch (`talkers` data set; [@R-hqmisc]).
    Categorical variables are created here with the
    `cut` function, to create
    `breaks=2` categories of `age` (young and
    old) and of `phraselength` (short and long).
```{r 5.3.1}
require(hqmisc)
data(talkers)
age.cat <- cut( talkers$age, breaks=2 )
phraselength.cat <- cut( talkers$nsyl, breaks=2 )
```

The hypothesis under study is that older speakers tend to produce
    shorter phrases. This hypothesis may be tested with a $\chi^2$ (chi
    square) test.\
```{r 5.3.2}
table( age.cat, phraselength.cat ) # show 2x2 table
chisq.test( age.cat, phraselength.cat ) 
```

The data in the table show that, as hypothesized, the odds of older talkers producing short phrases ($32/8$ or $4.0:1$) are indeed higher than the odds of younger talkers producing short phrases ($28/12$ or $2.3:1$). The effect is far from significant, however, and $H_0$ is not rejected.

## `aov`

This function performs a between-subjects analysis of variance, with
    only fixed factors [@john08] (For more complex
    analyses of variance having repeated measures, see Johnson 2008; for mixed effects models, see Chapter \@ref(ch:mixedeffects) and references cited there.)
    In the example below we create a
    response variable `aa` which is not normally distributed 
    (check
    with `hist`, `qqnorm`, etc).\
```{r 5.4.1}
a1<-rpois(20,lambda=2); a2<-rpois(20,lambda=4); a3<-rpois(20,lambda=6) 
aa <- c(a1,a2,a3) 
x1 <- as.factor(rep(1:3,each=20)) 
# x1 corresponds with the three different poisson distributions within aa
x2 <- as.factor(rep( rep(1:2,each=10), 3)) # no effect expected
summary( model1.aov <- aov(aa~x1*x2) )
```

